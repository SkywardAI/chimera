services:
  kirin:
    container_name: kirin
    restart: always
    build:
      dockerfile: Dockerfile
      context: ./chimera/
    environment:
      - ENVIRONMENT=${ENVIRONMENT}
      - DEBUG=${DEBUG}
      - BACKEND_SERVER_HOST=${BACKEND_SERVER_HOST}
      - BACKEND_SERVER_PORT=${BACKEND_SERVER_PORT}
      - BACKEND_SERVER_WORKERS=${BACKEND_SERVER_WORKERS}
      - BACKEND_SERVER_VERSION=${BACKEND_SERVER_VERSION}
      - IS_ALLOWED_CREDENTIALS=${IS_ALLOWED_CREDENTIALS}
      - API_TOKEN=${API_TOKEN}
      - AUTH_TOKEN=${AUTH_TOKEN}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_SUBJECT=${JWT_SUBJECT}
      - JWT_TOKEN_PREFIX=${JWT_TOKEN_PREFIX}
      - JWT_ALGORITHM=${JWT_ALGORITHM}
      - JWT_MIN=${JWT_MIN}
      - JWT_HOUR=${JWT_HOUR}
      - JWT_DAY=${JWT_DAY}
      - HASHING_ALGORITHM_LAYER_1=${HASHING_ALGORITHM_LAYER_1}
      - HASHING_ALGORITHM_LAYER_2=${HASHING_ALGORITHM_LAYER_2}
      - HASHING_SALT=${HASHING_SALT}
      - INFERENCE_ENG=${INFERENCE_ENG}
      - INFERENCE_ENG_PORT=${INFERENCE_ENG_PORT}
      - INFERENCE_ENG_VERSION=${INFERENCE_ENG_VERSION}
      - EMBEDDING_ENG=${EMBEDDING_ENG}
      - EMBEDDING_ENG_PORT=${EMBEDDING_ENG_PORT}
      - LANGUAGE_MODEL_NAME=${LANGUAGE_MODEL_NAME}
      - TIMEZONE=${TIMEZONE}
      - INSTRUCTION=${INSTRUCTION}
      - NUM_CPU_CORES=${NUM_CPU_CORES}
      - NUM_CPU_CORES_EMBEDDING=${NUM_CPU_CORES_EMBEDDING}
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME}
      - METRICS_PATHS=${METRICS_PATHS}
    volumes:
      - ./chimera/:/app/
    expose:
      - 8000
    ports:
      - 8000:8000

  llamacpp:
    container_name: ${INFERENCE_ENG}
    image: gclub/llama.cpp:${INFERENCE_ENG_VERSION}
    restart: always
    deploy:
      resources:
        reservations:
          cpus: "${NUM_CPU_CORES}"
    volumes:
      - "${DOCKER_VOLUME_DIRECTORY:-.}/data/models:/models"
    expose:
      - 8080
    ports:
      - 8080:8080
    command: ["-m", "models/${LANGUAGE_MODEL_NAME}","-c","8192"]
